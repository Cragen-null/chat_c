from fastapi import FastAPI, Request
from fastapi.responses import FileResponse, JSONResponse
import requests
import os
from dotenv import load_dotenv
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
import base64
import tempfile
import json

HISTORY_FILE = "chat_history.json"

# å±¥æ­´ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
def save_history():
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(chat_history, f, ensure_ascii=False, indent=2)

# å±¥æ­´ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
def load_history():
    global chat_history
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            chat_history = json.load(f)
    else:
        chat_history = []

# èµ·å‹•æ™‚ã«å±¥æ­´ã‚’ãƒ­ãƒ¼ãƒ‰
load_history()
   
load_dotenv()

app = FastAPI()

GROQ_API_KEY = os.getenv("GROQ_API_KEY")
GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"

# ==============================
# åŸºæœ¬è¨­å®š
# ==============================
AIVIS_URL = "http://127.0.0.1:10101"

AIVIS_SPEAKER = "0"  # ãƒœã‚¤ã‚¹IDï¼ˆ0ãªã©ã€ã‚¨ãƒ³ã‚¸ãƒ³ã®å‡ºåŠ›ã§ç¢ºèªï¼‰

# ==============================
# éŸ³å£°åˆæˆé–¢æ•°ï¼ˆAivisSpeechç”¨ï¼‰
# ==============================
def synthesize_aivis(text: str):
    try:
        STYLE_ID = "888753763"
        params = personality_data.get("speech_params", {})

        # ã‚¯ã‚¨ãƒªç”Ÿæˆ
        query_response = requests.post(
            f"{AIVIS_URL}/audio_query",
            params={"text": text, "speaker": STYLE_ID}
        )
        query_response.raise_for_status()
        query = query_response.json()

        # personalityã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é©ç”¨
        query.update({
            "speedScale": speech_params.get("speed", 0.96),
            "styleScale": speech_params.get("style_strength", 1.03),
            "intonationScale": speech_params.get("intonation", 0.9),
            "pitchScale": speech_params.get("pitch", -0.06),
            "volumeScale": speech_params.get("volume", 0.6),
            "prePhonemeLength": speech_params.get("pre_silence", 0.18),
            "postPhonemeLength": speech_params.get("post_silence", 0.25)
        })

        synth_response = requests.post(
            f"{AIVIS_URL}/synthesis",
            params={"speaker": STYLE_ID},
            data=json.dumps(query, ensure_ascii=False).encode("utf-8"),
            headers={"Content-Type": "application/json"},
        )
        synth_response.raise_for_status()
        return base64.b64encode(synth_response.content).decode("utf-8")

    except Exception as e:
        print("AivisSpeechéŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼:", e)
        return None


# ä¼šè©±å±¥æ­´ï¼ˆç°¡æ˜“ç‰ˆï¼‰
chat_history = []

# æ€§æ ¼è¨­å®š
BOT_PERSONALITY_PATH = os.getenv("BOT_PERSONALITY_PATH", "configs/personality_bella.json")
with open(BOT_PERSONALITY_PATH, "r", encoding="utf-8") as f:
    personality_data = json.load(f)

# systemãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”¨æ–‡å­—åˆ—ã«å¤‰æ›
traits_str = "\n- ".join(personality_data.get("personality_traits", []))
policy_str = "\n- ".join(personality_data.get("conversation_policy", []))
knowledge_str = "\n- ".join(personality_data.get("knowledge_scope", []))

BOT_PERSONALITY = f"""
ã‚ãªãŸã®åå‰ã¯ {personality_data['name']} ã§ã™ã€‚
{personality_data['greeting']}

ã€æ€§æ ¼ã€‘
- {traits_str}

ã€ä¼šè©±æ–¹é‡ã€‘
- {policy_str}

ã€çŸ¥è­˜ç¯„å›²ã€‘
- {knowledge_str}

æœ€åˆã®ç™ºè©±ã§ã¯ã€å¿…ãšè‡ªå·±ç´¹ä»‹ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
"""

# éŸ³å£°åˆæˆé–¢æ•°ã§ã¯speech_paramsã‚’å‚ç…§
speech_params = personality_data.get("speech_params", {})


# ç¾åœ¨ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚¦ãƒ³ãƒˆ
#app.mount("/static", StaticFiles(directory=os.path.join(BASE_DIR, "static")), name="static")
app.mount("/static", StaticFiles(directory="static"), name="static")

# ãƒ«ãƒ¼ãƒˆï¼ˆindex.htmlï¼‰
@app.get("/")
async def root():
    return FileResponse(os.path.join(BASE_DIR, "index.html"))
    #return FileResponse("chat.html") #å˜ç‹¬å‹•ä½œãƒ†ã‚¹ãƒˆç”¨
    
MAX_HISTORY = 10  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€10ä»¶ï¼‹Botè¿”ä¿¡10ä»¶ã‚’ä¿æŒã—ãŸã„å ´åˆã¯èª¿æ•´

@app.post("/chat")
async def chat(request: Request):
    global chat_history
    data = await request.json()
    user_message = data.get("message")

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€ã‚’å±¥æ­´ã«è¿½åŠ 
    chat_history.append({"role": "user", "content": user_message})
    while len(chat_history) > MAX_HISTORY * 2:
        chat_history.pop(0)

    messages = [{
    "role": "system",
    "content": f"ã‚ãªãŸã¯ {personality_data['name']} ã¨ã„ã†ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã§ã™ã€‚"
               f"å£èª¿: {personality_data['tone']}ã€"
               f"æ€§æ ¼: {personality_data['style']}ã€‚\n"
               f"ä»¥ä¸‹ã¯åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¾‹ã§ã™: {personality_data['greeting']}\n\n"
               f"{BOT_PERSONALITY}"
}] + chat_history
    

    # âœ… ã“ã“ãŒé‡è¦ï¼ï¼ˆé–¢æ•°ã®ä¸­ã«å…¥ã‚Œã‚‹ï¼‰
    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json",
    }

    payload = {
        "model": "llama-3.1-8b-instant",
        "messages": messages,
        "temperature": 0.7,
        "max_tokens": 512,
    }

    # ğŸ”¹ Groq APIå‘¼ã³å‡ºã—
    response = requests.post(GROQ_API_URL, headers=headers, json=payload)
    response.raise_for_status()
    bot_reply = response.json()["choices"][0]["message"]["content"]

    # ğŸ”¹ Botç™ºè¨€ã‚’å±¥æ­´ã«è¿½åŠ 
    chat_history.append({"role": "assistant", "content": bot_reply})
    save_history()  # å±¥æ­´ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜

    # ğŸ”¹ éŸ³å£°ç”Ÿæˆ
    audio_base64 = synthesize_aivis(bot_reply)

    return JSONResponse({
        "reply": bot_reply,
        "audio": audio_base64
    })



@app.get("/favicon.ico")
async def favicon():
    return FileResponse("static/favicon.ico")
